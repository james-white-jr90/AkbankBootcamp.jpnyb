{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.18","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpuV5e8","dataSources":[{"sourceId":3399185,"sourceType":"datasetVersion","datasetId":2049052}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/jamescookjr90/goruntusiniflandirmaakbankbootcamp?scriptVersionId=264218800\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 1. Giriş\n\n## Proje Hedefi\n\nAkbank Derin Öğrenme Bootcamp: Yeni Nesil Proje Kampı kapsamında bu notebook'ta görselleri verilen 5 farklı pirinç türünün sınıflandırılması için bir derin öğrenme modeli geliştirilmektedir. Keras kütüphanesi ile oluşturulan **Evrişimli Sinir Ağı (CNN)** modeli eğitilmekte ve performansı değerlendirilmektedir.\n\n## Veri Setine Genel Bakış\n\nÇalışmada, her biri 15,000 adet görüntü içeren 5 farklı pirinç sınıfından oluşan toplam 75,000 görüntülük dengeli bir veri seti kullanılmıştır. Görev, mevcut veri setini kullanarak pirinç türlerini yüksek doğrulukla sınıflandırabilen bir model tasarlamaktır.\n\n## Sınıflandırılacak Pirinç Türleri\n\n* Arborio\n* Basmati\n* Ipsala\n* Jasmine\n* Karacadag\n\nVeri seti hakkında daha fazla bilgi için aşağıdaki Kaggle bağlantısı kullanılabilir:\n[Rice Image Dataset](https://www.kaggle.com/datasets/muratkokludataset/rice-image-dataset)","metadata":{}},{"cell_type":"markdown","source":"# 2. Kütüphanelerin Yüklenmesi ve Veri Setinin Tanımlanması\n\nBu bölümde, veri analizi (`Pandas`, `NumPy`), veri görselleştirme (`Matplotlib`, `Seaborn`) ve derin öğrenme modeli (`TensorFlow`, `Keras`) için gerekli olan tüm Python kütüphaneleri çalışma ortamına dahil edilmektedir.","metadata":{}},{"cell_type":"code","source":"# Kütüphanelerin import edilmesi\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n\nDATA_DIR = '/kaggle/input/rice-image-dataset/Rice_Image_Dataset'\n\nprint(\"Kütüphaneler yüklendi ve veri setinin yolu tanımlandı.\")\nprint(\"Veri setindeki pirinç türleri (klasörler):\", os.listdir(DATA_DIR))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Kodun son satırı, bu dizine başarıyla erişildiğini ve içerisindeki pirinç türü klasörlerinin doğru bir şekilde listelendiğini doğrular.","metadata":{}},{"cell_type":"markdown","source":"## 2.1. Görüntü Yollarının Okunması ve DataFrame'e Aktarılması\n\nBu kod, veri setindeki tüm görüntülerin dosya yollarını (filepaths) ve etiketlerini (labels) okur ve bu bilgileri, sonraki adımlarda kolayca işlemek üzere bir pandas DataFrame düzenler.","metadata":{}},{"cell_type":"code","source":"filepaths = []\nlabels = []\n\nfor item in os.listdir(DATA_DIR):\n    item_path = os.path.join(DATA_DIR, item)\n    \n    if os.path.isdir(item_path):\n        for file in os.listdir(item_path):\n            filepath = os.path.join(item_path, file)\n            \n            filepaths.append(filepath)\n            labels.append(item)\n\ndf = pd.DataFrame({'filepath': filepaths, 'label': labels})\n\nprint(\"Veri tablosu başarıyla oluşturuldu.\")\nprint(f\"Toplam {len(df)} adet resim bulundu.\")\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 3. Veri Keşfi ve Görselleştirme (EDA)\nModeli eğitmeden önce veri setini anlaşılmalıdır. Bu hücrede, veri setinin temel özelliklerini ortaya çıkarmak için iki tür görselleştirme yapılmaktadır.\n\nİlk grafik, her sınıftaki görüntü sayısını göstererek veri setinin dengeli olduğunu doğrular. İkinci görselleştirme ise, modelin öğreneceği veriyi daha iyi anlamak için rastgele pirinç örnekleri sunar.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.countplot(data=df, x='label', order=df['label'].value_counts().index)\nplt.title('Sınıflardaki Görüntü Sayısı')\nplt.xticks(rotation=45)\nplt.show()\n\n# Birkaç tane örnek pirinç resmi gösterelim\nplt.figure(figsize=(12, 8))\nfor i in range(10):\n    # Rastgele bir resim seçiyoruz\n    random_index = np.random.randint(0, len(df))\n    image_path = df.loc[random_index, 'filepath']\n    image_label = df.loc[random_index, 'label']\n    \n    # Resmi okuyoruz ve gösteriyoruz\n    image = plt.imread(image_path)\n    plt.subplot(2, 5, i + 1)\n    plt.imshow(image)\n    plt.title(image_label)\n    plt.axis('off')\n\nplt.suptitle('Örnek Pirinç Görüntüleri', fontsize=16)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 4. Veri Setinin Eğitim ve Doğrulama Olarak Ayrılması\n\nModelin performansını doğru bir şekilde ölçebilmek için, veri setimizi ikiye ayırmamız gerekir: modelin öğrenmek için kullanacağı bir **eğitim seti** ve modelin performansını test etmek için kullanacağı, daha önce hiç görmediği bir **doğrulama seti**.\n\nBu kod hücresinde, `scikit-learn` kütüphanesinin `train_test_split` fonksiyonu kullanılarak veri setimiz **%80 eğitim** ve **%20 doğrulama** olacak şekilde bölünmektedir. `stratify` parametresi, bu bölme işlemi sırasında her iki sette de beş pirinç türünün orantılı bir şekilde dağılmasını garanti altına alır, bu da modelin daha adil bir şekilde eğitilmesini sağlar.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(\n    df,\n    test_size=0.2,         # %20 validation\n    stratify=df['label'],\n    random_state=42\n)\n\nprint(f\"Eğitim seti boyutu: {len(train_df)}\")\nprint(f\"Doğrulama seti boyutu: {len(valid_df)}\")\n\nprint(\"\\nEğitim sınıf dağılımı:\")\nprint(train_df['label'].value_counts())\n\nprint(\"\\nDoğrulama sınıf dağılımı:\")\nprint(valid_df['label'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4.1. Veri Çoğaltma (Data Augmentation) ve Veri Jeneratörlerinin Oluşturulması\n\nBu adımda, Keras'ın `ImageDataGenerator` sınıfı kullanılarak **Veri Çoğaltma (Data Augmentation)** işlemi tanımlanmaktadır. Bu işlem, eğitim setindeki her bir görüntüyü alıp, ona rastgele döndürme, yakınlaştırma, kaydırma gibi küçük değişiklikler yaparak ortaya çıkan resimi sanki yeni bir resim gibi modele sunar. Bu, modelin ezber yapmasını (overfitting) engellemenin en etkili yollarından biridir.\n\nDoğrulama seti ile modelin performansı, her zaman orijinal ve değiştirilmemiş resimler üzerinde ölçülmektedir.\n\nSon olarak, bu kurallara göre hazırlanan eğitim ve doğrulama DataFrame'leri, `.flow_from_dataframe()` metodu ile modele veri akışı sağlayacak olan **jeneratörlere** dönüştürülür. Bu jeneratörlerin veriyi 32'lik gruplar (`batch`) halinde ve `(128, 128)` boyutuna getirilmiş olarak modele verimli bir şekilde sunması amaçlanır.","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    rescale=1./255,          # Piksel değerlerini 0-1 arasına getirir\n    rotation_range=20,       # Resimleri rastgele 20 derece döndürür\n    width_shift_range=0.2,   # Resimleri yatayda kaydırır\n    height_shift_range=0.2,  # Resimleri dikeyde kaydırır\n    shear_range=0.2,         # Resimleri eğer\n    zoom_range=0.2,          # Resimlere rastgele zoom yapar\n    horizontal_flip=True,    # Resimleri yatayda çevirir\n    fill_mode='nearest'\n)\n\n# Doğrulama verisi için çoğaltma yapmıyoruz, sadece piksel değerlerini 0-1 arasına getiriyoruz\nvalid_datagen = ImageDataGenerator(\n    rescale=1./255\n)\n\nIMG_SIZE = (128, 128)\nBATCH_SIZE = 32\n\ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=IMG_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\nvalid_generator = valid_datagen.flow_from_dataframe(\n    dataframe=valid_df,\n    x_col='filepath',\n    y_col='label',\n    target_size=IMG_SIZE,\n    class_mode='categorical',\n    batch_size=BATCH_SIZE,\n    shuffle=False  # validation set sabit kalsın\n)\n\nprint(\"Veri generator'ları başarıyla oluşturuldu.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 5. Evrişimli Sinir Ağı (CNN) Model Mimarisi\n\nBu adımda, Keras `Sequential` API'si ile projenin temelini oluşturan CNN modeli katman katman oluşturulmuştur. Model, görüntülerden hiyerarşik özellikler çıkarmak için üç adet `Conv2D` ve `MaxPooling2D` bloğu içerir.\n\nAşırı öğrenmeyi (overfitting) engellemek ve modelin genelleme yeteneğini artırmak için kritik bir `Dropout` katmanı eklenmiştir. Son olarak, `Flatten` ve `Dense` katmanları ile özellikler işlenir. 5 farklı tür  için `softmax` aktivasyonuna sahip bir çıkış katmanı, her pirinç türü için bir olasılık tahmini üretir.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(5, activation='softmax'))\n\n# Modelin mimarisini özet olarak görelim\nmodel.summary()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5.1 Modelin Derlenmesi\n\nModel mimarisi oluşturulduktan sonra, eğitim sürecine hazırlık için **derlenmesi** gerekir. Bu adımda, modele öğrenme sürecinde hangi araçları kullanacağı belirtilir:\n\n- **Optimizer (`adam`):** Modelin, yaptığı hatalardan ders çıkararak ağırlıklarını nasıl güncelleyeceğini belirleyen algoritmadır. `Adam`, çoğu problem için verimli ve etkili bir başlangıç noktasıdır.\n- **Loss Fonksiyonu (`categorical_crossentropy`):** Modelin tahminlerinin gerçek değerlerden ne kadar saptığını ölçen matematiksel bir fonksiyondur. Model, eğitim boyunca bu \"kayıp\" değerini en aza indirmeye çalışır.\n- **Metrikler (`accuracy`):** Eğitim ve test sırasında modelin performansını izlemek için kullanılan ölçüttür. Burada, modelin doğru tahmin yapma oranı olan **doğruluk (accuracy)** metriğini takip edeceğiz.","metadata":{}},{"cell_type":"code","source":"model.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"Model başarıyla derlendi.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 6. Modelin Akıllı Yardımcılar (Callbacks) ile Eğitilmesi\n\nBu bölümde model, `model.fit()` fonksiyonu ile hazırlanan veri jeneratörleri ile eğitilmektedir. Modelin sadece ezber yapmasını engellemek ve en iyi performansı gösteren versiyonunu yakalamak için iki kritik **Callback** (akıllı yardımcı) kullanılmıştır.\n\n1.  **`EarlyStopping`:** Bu yardımcı, modelin doğrulama seti üzerindeki performansını (`val_loss`) her epoch sonunda izler. Performansta belirli bir süre (`patience=5`) boyunca bir iyileşme görmezse, eğitimi otomatik olarak durdurur. Bu, gereksiz yere uzun süren eğitimleri engeller ve modelin en iyi olduğu \"zirve anını\" kaçırmamasını sağlar. `restore_best_weights=True` parametresi sayesinde, eğitim durduğunda modelin en başarılı olduğu andaki ağırlıkları geri yüklenir.\n\n2.  **`ModelCheckpoint`:** Bu yardımcı da `val_loss` metriğini izler ve sadece bir önceki en iyi skordan daha iyi bir sonuç elde edildiğinde modeli `best_model.keras` adıyla diske kaydeder. Bu, eğitim süreci boyunca elde edilen en iyi modelin her zaman elimizin altında olmasını garanti eder.\n\nBu iki yardımcı sayesinde model, maksimum 30 epoch'a kadar, aşırı öğrenmeye (overfitting) karşı korunarak ve en iyi performansı hedeflenerek eğitilmiş olur.","metadata":{}},{"cell_type":"code","source":"from tensorflow. keras.callbacks import EarlyStopping, ModelCheckpoint\n\nearly_stop = EarlyStopping(\n    monitor='val_loss',\n    patience=5,           # 5 epoch boyunca iyileşme yoksa durur\n    restore_best_weights=True\n)\n\n# ModelCheckpoint\ncheckpoint = ModelCheckpoint(\n    filepath='best_model.keras',\n    monitor='val_loss',\n    save_best_only=True,\n    verbose=1\n)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=valid_generator,\n    epochs=30,\n    callbacks=[early_stop, checkpoint]\n)\nprint(\"Model başarıyla eğitildi.\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.1. Modelin Öğrenme Sürecinin Görselleştirilmesi\n\nBu adımda, modelin eğitim süreci boyunca kaydettiği doğruluk (`accuracy`) ve kayıp (`loss`) metrikleri görselleştirilir. Çizdirilen bu grafikler, eğitim ve doğrulama eğrilerinin seyrini göstererek modelin öğrenme performansını ve olası bir aşırı öğrenme (overfitting) durumunu hızlıca analiz etmemizi sağlar.","metadata":{}},{"cell_type":"code","source":"hist_df = pd.DataFrame(history.history)\n\n# Doğruluk (Accuracy) grafiği\nplt.figure(figsize=(12, 5))\nplt.subplot(1, 2, 1)\nplt.plot(hist_df['accuracy'], label='Eğitim Doğruluğu')\nplt.plot(hist_df['val_accuracy'], label='Doğrulama Doğruluğu')\nplt.title('Doğruluk Grafiği')\nplt.xlabel('Epoch')\nplt.ylabel('Doğruluk')\nplt.legend()\n\n# Kayıp (Loss) grafiği\nplt.subplot(1, 2, 2)\nplt.plot(hist_df['loss'], label='Eğitim Kaybı')\nplt.plot(hist_df['val_loss'], label='Doğrulama Kaybı')\nplt.title('Kayıp Grafiği')\nplt.xlabel('Epoch')\nplt.ylabel('Kayıp')\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6.2. Model Performansının Detaylı Değerlendirilmesi\n\nBu adımda, eğitimde kaydedilen en iyi model (`best_model.keras`) dosyadan geri yüklenerek performansı analiz edilir. Bu yöntem, sonuçların her zaman modelin en başarılı versiyonuna ait olmasını garanti eder.\n\nBu yüklenmiş model ile doğrulama seti üzerinde tahminler yapılarak iki önemli çıktı üretilir: \n1.  **`Sınıflandırma Raporu (Classification Report)`:** Her sınıfın başarısını detaylandırır \n2.  **`Karışıklık Matrisi (Confusion Matrix)`:** Modelin yaptığı hataları görselleştirir\n\nBu metrikler, modelin genel doğruluğunu ve hangi sınıflarda zorlandığını net bir şekilde görmemizi sağlar.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model # <-- Kütüphaneyi ekliyoruz\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\nprint(\"Kaydedilmiş en iyi model olan 'best_model.keras' yükleniyor...\")\nbest_model = load_model('best_model.keras')\nprint(\"Model başarıyla yüklendi.\")\n\nsteps = int(np.ceil(valid_generator.n / BATCH_SIZE))\n\npredictions = best_model.predict(valid_generator, steps=steps)\n\n\npredicted_classes = np.argmax(predictions, axis=1)\n\ntrue_classes = valid_generator.classes\nclass_labels = list(valid_generator.class_indices.keys())\n\nprint(\"\\nClassification Report\\n\")\nprint(classification_report(true_classes, predicted_classes, target_names=class_labels))\n\ncm = confusion_matrix(true_classes, predicted_classes)\n\n# Confusion Matrix'i görselleştiriyoruz\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)\nplt.title('En İyi Modelin (best_model.keras) Confusion Matrix Sonucu')\nplt.xlabel('Tahmin Edilen Sınıf')\nplt.ylabel('Gerçek Sınıf')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-09-26T20:42:00.287Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# 7. Sonuç ve Değerlendirme\n\nBu projede 75,000 görüntüden oluşan \"Rice Image Dataset\"ini kullanarak beş farklı pirinç türünü ayırt edebilen yüksek performanslı bir CNN modeli geliştirilmesi amaçlanmaktadır.\n\nProjede, veri hazırlama, veri çoğaltma (data augmentation) ve katman katman bir CNN mimarisi kurma gibi derin öğrenmenin temel adımları uygulanmaktadır. Eğitim aşamasında, modelin ezber yapmasını (overfitting) engellemek için `EarlyStopping` gibi akıllı yardımcılar (callbacks) kullanılmaktadır. Böylece modelin en verimli noktada durmasını sağlanmaktadır.\n\nBu model, daha önce görmediği doğrulama verileri üzerinde **%99 gibi oldukça başarılı bir doğruluk oranına ulaşmaktadır.** Ayrıca, Grad-CAM analizi ile model hem doğru tahmin yapmakta hem de karar verirken mantıklı bir şekilde pirinç tanelerinin kendisine odaklanmaktadır.\n\n Bu notebook, bir derin öğrenme projesinin nasıl hayata geçirilebileceğini göstermektedir.","metadata":{}}]}